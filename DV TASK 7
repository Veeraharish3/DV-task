{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOK5uslIFpDfZ+4/neWU8dJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"STxRaL51dwS-","executionInfo":{"status":"error","timestamp":1761644360375,"user_tz":-330,"elapsed":6036,"user":{"displayName":"PANJAGALLA VEERA HARISH,CSE(2022) Vel Tech, Chennai","userId":"08649764122198622287"}},"outputId":"5df3c8bd-d6a2-45c1-c1b9-2602c60af3fc"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'feedback_text (1).txt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2979625105.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ---- Step 1: Load Text ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feedback_text (1).txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'feedback_text (1).txt'"]}],"source":["from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import nltk\n","\n","# Download necessary resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# ---- Step 1: Load Text ----\n","with open('feedback_text (1).txt', 'r') as file:\n","    text = file.read()\n","\n","# ---- Step 2: Preprocess Text ----\n","tokens = word_tokenize(text.lower())\n","filtered = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n","\n","# ---- Step 3: Create Word Cloud ----\n","wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(filtered))\n","\n","# ---- Step 4: Plot ----\n","plt.figure(figsize=(10, 6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","plt.title(\"Word Cloud Visualization\", fontsize=16)\n","plt.show()"]}]}